{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0399d1cc73644b9c8e7484462cd4f9b3b32f61f571975f1cd01f67b06c060b9c6",
   "display_name": "Python 3.7.10 64-bit ('scispacy': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import numpy as np\n",
    "#nltk.download('punkt')\n",
    "from textblob import Word\n",
    "pd.options.display.width = 0\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "all_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "pd.set_option('display.max_rows', 6000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "#pd.describe_option('display')\n",
    "# import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('clergy', 0.48717948717948717),\n",
       " ('gallery', 0.28205128205128205),\n",
       " ('alley', 0.1282051282051282),\n",
       " ('allegro', 0.05128205128205128),\n",
       " ('allegory', 0.02564102564102564),\n",
       " ('allege', 0.02564102564102564)]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "def find_in_english_dict(text):\n",
    "    for w in word_tokenize(text):\n",
    "        if Word(w.strip().lower()).spellcheck()[0][1]!=1.0 and len(re.findall(r\"[A-Z]{2,}\", w))>0:\n",
    "          # print(w)\n",
    "          return True\n",
    "    return False\n",
    "\n",
    "find_in_english_dict('HYPERTHROIDSM')\n",
    "Word('allergy'.strip().lower()).spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(  text_id text      cui_l      cui_g      cui_d  cui_len       cui_g_l   ID  \\\n",
       " 0      A1    a  [1, 2, 5]  [1, 2, 3]  [1, 2, 4]        3  [1, 2, 3, 4]  ID0   \n",
       " 1      A2    b     [2, 5]     [2, 3]        [3]        2        [2, 3]  ID1   \n",
       " 2      A3    c         []        [4]         []        0           [4]  ID2   \n",
       " 3      A4    d         []         []         []        0            []  ID3   \n",
       " \n",
       "    cui_final  \n",
       " 0  [1, 2, 5]  \n",
       " 1     [2, 5]  \n",
       " 2        [4]  \n",
       " 3         []  ,\n",
       "     ID cui_final\n",
       " 0  ID0         1\n",
       " 1  ID0         2\n",
       " 2  ID0         5\n",
       " 3  ID1         2\n",
       " 4  ID1         5\n",
       " 5  ID2         4\n",
       " 6  ID3       NaN)"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "l = {'text_id':['A1','A2','A3','A4'], 'text':['a','b','c', 'd'], 'cui_l':[[1,2,5],[2,5], [],[]],\n",
    "    'cui_g':[[1,2,3],[2,3],[4],[]], 'cui_d':[[1,2,4],[3], [], []]}\n",
    "df = pd.DataFrame(data=l)\n",
    "df['cui_len']=df['cui_l'].apply(lambda x: len(x))\n",
    "df['cui_g_l']=(df['cui_g']+df['cui_d']).apply(lambda x: list(set(x)))\n",
    "df['ID'] = ['ID'+ str(x) for x in df.index.tolist()]\n",
    "df['cui_final'] = np.where(df['cui_len']!=0, df['cui_l'], df['cui_g_l'])\n",
    "df_id_cui = df[['ID','cui_final']]\n",
    "df, df_id_cui.explode('cui_final', ignore_index=True), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}